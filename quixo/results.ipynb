{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import Game, Move, Player\n",
    "from players.random_player import RandomPlayer\n",
    "from players.minimax_v1_player import MinimaxPlayerV1\n",
    "from players.minimax_v2_player import MinimaxPlayerV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battle(player1: Player, player2: Player, games, print_results=False) -> int:\n",
    "    count = 0\n",
    "    for i in range(games):\n",
    "        g = Game()\n",
    "        winner = g.play(player1, player2)\n",
    "        if winner == 0:\n",
    "            count += 1\n",
    "        if print_results:\n",
    "            print(f\"Player 0 wins {count} out of {i+1} games\", end=\"\\r\")\n",
    "    if print_results:\n",
    "        print(f\"Player 0 wins {count} out of {i+1} games\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def tournament(agents, games=100):\n",
    "    # Create a PrettyTable instance\n",
    "    table = PrettyTable()\n",
    "\n",
    "    # Define table columns\n",
    "    table.field_names = [\"Battle\", \"Wins\"]\n",
    "\n",
    "    # Add data to the table\n",
    "    for agent1 in range(len(agents)):\n",
    "        for agent2 in range(agent1+1, len(agents)):\n",
    "            wins = battle(agents[agent1], agents[agent2], games)\n",
    "            table.add_row([f\"{agent1} vs {agent2}\", str((wins/games)*100)+\"%\"])\n",
    "    # Print the table\n",
    "    print(\"Tournament Results over {} games\".format(games))\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m agents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     MinimaxPlayerV1(),\n\u001b[1;32m      3\u001b[0m     MinimaxPlayerV2(),\n\u001b[1;32m      4\u001b[0m     RandomPlayer()\n\u001b[1;32m      5\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtournament\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 13\u001b[0m, in \u001b[0;36mtournament\u001b[0;34m(agents, games)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(agents)):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m agent2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(agent1\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(agents)):\n\u001b[0;32m---> 13\u001b[0m         wins \u001b[38;5;241m=\u001b[39m \u001b[43mbattle\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         table\u001b[38;5;241m.\u001b[39madd_row([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m((wins\u001b[38;5;241m/\u001b[39mgames)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Print the table\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m, in \u001b[0;36mbattle\u001b[0;34m(player1, player2, games, print_results)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(games):\n\u001b[1;32m      4\u001b[0m     g \u001b[38;5;241m=\u001b[39m Game()\n\u001b[0;32m----> 5\u001b[0m     winner \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m winner \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/game.py:97\u001b[0m, in \u001b[0;36mGame.play\u001b[0;34m(self, player1, player2)\u001b[0m\n\u001b[1;32m     95\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok:\n\u001b[0;32m---> 97\u001b[0m     from_pos, slide \u001b[38;5;241m=\u001b[39m \u001b[43mplayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_player_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_move\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__move(from_pos, slide, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_player_idx)\n\u001b[1;32m     99\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_winner()\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/players/minimax_v2_player.py:52\u001b[0m, in \u001b[0;36mMinimaxPlayerV2.make_move\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     50\u001b[0m board \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_board()\n\u001b[1;32m     51\u001b[0m player \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mget_current_player()\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/players/minimax_v2_player.py:109\u001b[0m, in \u001b[0;36mMinimaxPlayerV2.minimax\u001b[0;34m(self, player, board)\u001b[0m\n\u001b[1;32m    107\u001b[0m best_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_actions(board, player):\n\u001b[0;32m--> 109\u001b[0m     new_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_v\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_v \u001b[38;5;241m>\u001b[39m v \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    117\u001b[0m         new_v \u001b[38;5;241m==\u001b[39m v\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m board[best_action[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], best_action[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m==\u001b[39m player\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m board[action[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], action[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m!=\u001b[39m player\n\u001b[1;32m    120\u001b[0m     ):\n\u001b[1;32m    121\u001b[0m         v \u001b[38;5;241m=\u001b[39m new_v\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/players/minimax_v2_player.py:91\u001b[0m, in \u001b[0;36mMinimaxPlayerV2.min_v\u001b[0;34m(self, board, alpha, beta, depth, player)\u001b[0m\n\u001b[1;32m     87\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossible_actions(board, player):\n\u001b[1;32m     89\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m     90\u001b[0m         v,\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_v\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m     beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(beta, v)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m alpha \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m beta:\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/players/minimax_v2_player.py:67\u001b[0m, in \u001b[0;36mMinimaxPlayerV2.max_v\u001b[0;34m(self, board, alpha, beta, depth, player)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutility(winner)\n\u001b[1;32m     66\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpossible_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     68\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m     69\u001b[0m         v,\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_v(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         ),\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(alpha, v)\n",
      "File \u001b[0;32m~/Files/2023-2/CI/Computational-Intelligence/quixo/players/minimax_v2_player.py:59\u001b[0m, in \u001b[0;36mMinimaxPlayerV2.possible_actions\u001b[0;34m(self, board, player)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# check if the piece can be moved by the current player\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m board[i[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], i[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m board[i[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], i[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m==\u001b[39m player:\n\u001b[0;32m---> 59\u001b[0m         \u001b[43mpos_actions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pos_actions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agents = [\n",
    "    MinimaxPlayerV1(),\n",
    "    MinimaxPlayerV2(),\n",
    "    RandomPlayer()\n",
    "]\n",
    "tournament(agents, games=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
